{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from nlp_utils import preprocess_sentence, TextTokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 주의!!!!\n",
    "\n",
    "## 집에 슈퍼컴퓨터가 있다면 돌려보기를..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>안녕하세요</td>\n",
       "      <td>️️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이거 해봐요&gt;&lt;</td>\n",
       "      <td>나의 직장인 멘탈 성향은  [안챙겨도 잘커요, 탕비실 선인장] 당신의 멘탈 성향은 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>오 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ오 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 안챙겨도 잘커요 너무 맞는데요ㅜㅜ? 자...</td>\n",
       "      <td>ㅋㅌㅋㅋㅋㅋㅋㅌㅋㅋㅋㅋ 아녜여 챙겨주세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ㅋㅋㅋㅋㅋ당연하쥬ㅋㅋㅋㅋㅋ당연하쥬 누굴 챙길 여유는 저도 없는거같지만 그러나 점심 ...</td>\n",
       "      <td>그렇게 큰 권한을 주신다구요??그렇게 큰 권한을 주신다구요?? name1님 완전 대인배</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>목요일 점심메뉴도 생각해오세요 크크 전 닭가슴살 먹을거지만,,</td>\n",
       "      <td>흠 그럼 저도흠 그럼 저도 한번 도시락을 싸올까요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Q  \\\n",
       "0                                             안녕하세요    \n",
       "1                                          이거 해봐요><    \n",
       "2  오 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ오 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 안챙겨도 잘커요 너무 맞는데요ㅜㅜ? 자...   \n",
       "3  ㅋㅋㅋㅋㅋ당연하쥬ㅋㅋㅋㅋㅋ당연하쥬 누굴 챙길 여유는 저도 없는거같지만 그러나 점심 ...   \n",
       "4                목요일 점심메뉴도 생각해오세요 크크 전 닭가슴살 먹을거지만,,    \n",
       "\n",
       "                                                   A  \n",
       "0                                                ️️   \n",
       "1  나의 직장인 멘탈 성향은  [안챙겨도 잘커요, 탕비실 선인장] 당신의 멘탈 성향은 ...  \n",
       "2                            ㅋㅌㅋㅋㅋㅋㅋㅌㅋㅋㅋㅋ 아녜여 챙겨주세요   \n",
       "3  그렇게 큰 권한을 주신다구요??그렇게 큰 권한을 주신다구요?? name1님 완전 대인배   \n",
       "4                       흠 그럼 저도흠 그럼 저도 한번 도시락을 싸올까요   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./final_dataset.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안녕하세요', '이거 해봐요><', '오 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ오 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 안챙겨도 잘커요 너무 맞는데요ㅜㅜ ? 자세한 내용은 더 알아가야겟지만~~', 'ㅋㅋㅋㅋㅋ당연하쥬ㅋㅋㅋㅋㅋ당연하쥬 누굴 챙길 여유는 저도 없는거같지만 그러나 점심 메뉴는 언제든 권한을 드릴게여  ! ! ! !', '목요일 점심메뉴도 생각해오세요 크크 전 닭가슴살 먹을거지만 , ,']\n",
      "['️️', '나의 직장인 멘탈 성향은  [안챙겨도 잘커요 , 탕비실 선인장] 당신의 멘탈 성향은 어떠신가요 ? 지금 테스트해보세요 ! 나의 직장인 멘탈 성향은  [안챙겨도 잘커요 , 탕비실 선인장] 당신의 멘탈 성향은 어떠신가요 ? 지금 테스트해보세요 !  아앗 . . .', 'ㅋㅌㅋㅋㅋㅋㅋㅌㅋㅋㅋㅋ 아녜여 챙겨주세요', '그렇게 큰 권한을 주신다구요 ? ?그렇게 큰 권한을 주신다구요 ? ? name1님 완전 대인배', '흠 그럼 저도흠 그럼 저도 한번 도시락을 싸올까요']\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "for sentence in train_data[\"Q\"]:\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    questions.append(sentence)\n",
    "\n",
    "answers = []\n",
    "for sentence in train_data[\"A\"]:\n",
    "    sentence = preprocess_sentence(sentence)    \n",
    "    answers.append(sentence)\n",
    "\n",
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_to_file(\"tokenizing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([881171], [881172])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "\n",
    "START_TOKEN, END_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Length 50\n",
    "MAX_LENGTH = 50\n",
    "\n",
    "# Tokenizing / Integer Encoding / <SOS> <EOS> Token / Padding\n",
    "def tokenize_and_filter(questions,answers):\n",
    "        tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "        for (input, output) in zip(questions, answers):\n",
    "            input = START_TOKEN + tokenizer.encode(input) + END_TOKEN\n",
    "            output = START_TOKEN + tokenizer.encode(output) + END_TOKEN\n",
    "\n",
    "            tokenized_inputs.append(input)\n",
    "            tokenized_outputs.append(output)\n",
    "\n",
    "        \n",
    "        # Padding\n",
    "        tokenized_inputs = pad_sequences(tokenized_inputs, maxlen=MAX_LENGTH, padding=\"post\")\n",
    "        tokenized_outputs = pad_sequences(tokenized_outputs, maxlen=MAX_LENGTH, padding=\"post\")\n",
    "\n",
    "\n",
    "        return tokenized_inputs, tokenized_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터의 크기:(833577, 50)\n",
      "답변 데이터의 크기:(833577, 50)\n"
     ]
    }
   ],
   "source": [
    "print(f'질문 데이터의 크기:{questions.shape}')\n",
    "print(f'답변 데이터의 크기:{answers.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
    "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# Decoder real sequence has to remove <SOS> token\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # decoder input. Last Padding Token removed\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:] # First Token removed. <sos> token gone\n",
    "    }\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[881171  39268 881172      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n",
      "[[881171  39268 881172      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0]]\n",
      "[[ 39268 881172      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "NUM_LAYERS = 6\n",
    "D_MODEL = 512\n",
    "NUM_HEADS = 8\n",
    "DFF = 1024\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__RandomUniform_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[881173,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13636/3144437745.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model = transformer(\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvocab_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YSH\\Documents\\programming\\AGI\\transformer.py\u001b[0m in \u001b[0;36mtransformer\u001b[1;34m(vocab_size, num_layers, dff, d_model, num_heads, dropout, name)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;31m# Encoder's Output enc_outputs. Transfer to Decoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m     \u001b[0menc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[1;31m# Decoder's Output dec_outputs. Transfer to Final Layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YSH\\Documents\\programming\\AGI\\transformer.py\u001b[0m in \u001b[0;36mencoder\u001b[1;34m(vocab_size, num_layers, dff, d_model, num_heads, dropout, name)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;31m# Positional Encoding + Dropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m     \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._generator.uniform(\n\u001b[0;32m   1919\u001b[0m           shape=shape, minval=minval, maxval=maxval, dtype=dtype)\n\u001b[1;32m-> 1920\u001b[1;33m     return tf.random.uniform(\n\u001b[0m\u001b[0;32m   1921\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1922\u001b[0m         seed=self.make_legacy_seed())\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__RandomUniform_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[881173,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]"
     ]
    }
   ],
   "source": [
    "from transformer import transformer\n",
    "\n",
    "model = transformer(\n",
    "\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint_path = \"training_1/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# save weights in each five epochs\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_weights_only=True, save_best_only=True)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_weights_only=True, period=3)\n",
    "\n",
    "# model.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import CustomSchedule, loss_function\n",
    "\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "model.fit(dataset, epochs=EPOCHS, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9585e0e58f3ada4c387d89b399b9d9bb88b52954ed4e2235f58d5a052e970ed6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
