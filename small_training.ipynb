{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nlp_utils import preprocess_sentence, TextTokenizing\n",
    "from transformer import transformer, CustomSchedule, loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>안녕하세요</td>\n",
       "      <td>️️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이거 해봐요&gt;&lt;</td>\n",
       "      <td>나의 직장인 멘탈 성향은  [안챙겨도 잘커요, 탕비실 선인장] 당신의 멘탈 성향은 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>오 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ오 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 안챙겨도 잘커요 너무 맞는데요ㅜㅜ? 자...</td>\n",
       "      <td>ㅋㅌㅋㅋㅋㅋㅋㅌㅋㅋㅋㅋ 아녜여 챙겨주세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ㅋㅋㅋㅋㅋ당연하쥬ㅋㅋㅋㅋㅋ당연하쥬 누굴 챙길 여유는 저도 없는거같지만 그러나 점심 ...</td>\n",
       "      <td>그렇게 큰 권한을 주신다구요??그렇게 큰 권한을 주신다구요?? name1님 완전 대인배</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>목요일 점심메뉴도 생각해오세요 크크 전 닭가슴살 먹을거지만,,</td>\n",
       "      <td>흠 그럼 저도흠 그럼 저도 한번 도시락을 싸올까요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Q  \\\n",
       "0                                             안녕하세요    \n",
       "1                                          이거 해봐요><    \n",
       "2  오 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ오 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 안챙겨도 잘커요 너무 맞는데요ㅜㅜ? 자...   \n",
       "3  ㅋㅋㅋㅋㅋ당연하쥬ㅋㅋㅋㅋㅋ당연하쥬 누굴 챙길 여유는 저도 없는거같지만 그러나 점심 ...   \n",
       "4                목요일 점심메뉴도 생각해오세요 크크 전 닭가슴살 먹을거지만,,    \n",
       "\n",
       "                                                   A  \n",
       "0                                                ️️   \n",
       "1  나의 직장인 멘탈 성향은  [안챙겨도 잘커요, 탕비실 선인장] 당신의 멘탈 성향은 ...  \n",
       "2                            ㅋㅌㅋㅋㅋㅋㅋㅌㅋㅋㅋㅋ 아녜여 챙겨주세요   \n",
       "3  그렇게 큰 권한을 주신다구요??그렇게 큰 권한을 주신다구요?? name1님 완전 대인배   \n",
       "4                       흠 그럼 저도흠 그럼 저도 한번 도시락을 싸올까요   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./final_dataset.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안녕하세요', '이거 해봐요><', '오 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ오 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 안챙겨도 잘커요 너무 맞는데요ㅜㅜ ? 자세한 내용은 더 알아가야겟지만~~']\n",
      "['안녕하세요', '이거 해봐요><', '오 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ오 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 안챙겨도 잘커요 너무 맞는데요ㅜㅜ ? 자세한 내용은 더 알아가야겟지만~~']\n"
     ]
    }
   ],
   "source": [
    "questions = [preprocess_sentence(q) for q in train_data[\"Q\"]]\n",
    "answers = [preprocess_sentence(a) for a in train_data[\"A\"]]\n",
    "\n",
    "\n",
    "print(questions[:3])\n",
    "print(questions[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Small Model -> Small Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = questions[:50000]\n",
    "answers = answers[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions+answers, target_vocab_size=2**16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_to_file(\"super_small_vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.load_from_file(\"super_small_vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([62144], [62145])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size+1]\n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "\n",
    "START_TOKEN, END_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 50\n",
    "\n",
    "def tokenize_and_filter(questions, answers):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (input, output) in zip(questions, answers):\n",
    "        input = START_TOKEN + tokenizer.encode(input) + END_TOKEN\n",
    "        output = START_TOKEN + tokenizer.encode(output) + END_TOKEN\n",
    "\n",
    "        tokenized_inputs.append(input)\n",
    "        tokenized_outputs.append(output)\n",
    "    \n",
    "    tokenized_inputs = pad_sequences(tokenized_inputs, maxlen=MAX_LENGTH, padding=\"post\")\n",
    "    tokenized_outputs = pad_sequences(tokenized_outputs, maxlen=MAX_LENGTH, padding=\"post\")\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터의 크기:(50000, 50)\n",
      "답변 데이터의 크기:(50000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(f'질문 데이터의 크기:{questions.shape}')\n",
    "print(f'답변 데이터의 크기:{answers.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
    "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# Decoder real sequence has to remove <SOS> token\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # decoder input. Last Padding Token removed\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:] # First Token removed. <sos> token gone\n",
    "    }\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62144 14444 62145     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n",
      "[[62144 14444 62145     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]]\n",
      "[[14444 62145     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperparameters import NUM_LAYERS, D_MODEL, NUM_HEADS, DFF, DROPOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 62146, 256)\n",
      "(1, 62146, 256)\n"
     ]
    }
   ],
   "source": [
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, None, 256)    16963584    ['inputs[0][0]',                 \n",
      "                                                                  'enc_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
      "                                e)                                                                \n",
      "                                                                                                  \n",
      " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, None, 256)    17490944    ['dec_inputs[0][0]',             \n",
      "                                                                  'encoder[0][0]',                \n",
      "                                                                  'look_ahead_mask[0][0]',        \n",
      "                                                                  'dec_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, None, 62146)  15971522    ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 50,426,050\n",
      "Trainable params: 50,426,050\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint_path = \"training_small/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# save weights in each five epochs\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_weights_only=True, save_best_only=True)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_weights_only=True, save_freq=3)\n",
    "\n",
    "# model.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "  2/782 [..............................] - ETA: 4:41 - loss: 2.5362 - accuracy: 0.0000e+00   \n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "  5/782 [..............................] - ETA: 10:29 - loss: 2.6307 - accuracy: 0.0000e+00\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "  8/782 [..............................] - ETA: 12:04 - loss: 2.5406 - accuracy: 0.0000e+00\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 11/782 [..............................] - ETA: 12:26 - loss: 2.5923 - accuracy: 0.0000e+00\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 14/782 [..............................] - ETA: 12:15 - loss: 2.5869 - accuracy: 0.0000e+00\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 17/782 [..............................] - ETA: 12:07 - loss: 2.6148 - accuracy: 0.0000e+00\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 20/782 [..............................] - ETA: 11:57 - loss: 2.6214 - accuracy: 0.0000e+00\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 23/782 [..............................] - ETA: 11:50 - loss: 2.6101 - accuracy: 0.0000e+00\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 26/782 [..............................] - ETA: 11:42 - loss: 2.6122 - accuracy: 0.0000e+00\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 29/782 [>.............................] - ETA: 11:35 - loss: 2.6293 - accuracy: 0.0000e+00\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 32/782 [>.............................] - ETA: 11:29 - loss: 2.6134 - accuracy: 0.0000e+00\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 35/782 [>.............................] - ETA: 11:24 - loss: 2.6213 - accuracy: 0.0000e+00\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 38/782 [>.............................] - ETA: 11:20 - loss: 2.6111 - accuracy: 1.1748e-04\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 41/782 [>.............................] - ETA: 11:26 - loss: 2.5988 - accuracy: 5.1332e-04\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 44/782 [>.............................] - ETA: 11:23 - loss: 2.6166 - accuracy: 0.0015   \n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 47/782 [>.............................] - ETA: 11:32 - loss: 2.6109 - accuracy: 0.0027\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 50/782 [>.............................] - ETA: 11:24 - loss: 2.6008 - accuracy: 0.0038\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 53/782 [=>............................] - ETA: 11:20 - loss: 2.5895 - accuracy: 0.0047\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 56/782 [=>............................] - ETA: 11:26 - loss: 2.5719 - accuracy: 0.0055\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 59/782 [=>............................] - ETA: 11:19 - loss: 2.5678 - accuracy: 0.0063\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 62/782 [=>............................] - ETA: 11:15 - loss: 2.5733 - accuracy: 0.0070\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 65/782 [=>............................] - ETA: 11:10 - loss: 2.5714 - accuracy: 0.0076\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 68/782 [=>............................] - ETA: 11:09 - loss: 2.5612 - accuracy: 0.0082\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 71/782 [=>............................] - ETA: 11:06 - loss: 2.5762 - accuracy: 0.0087\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 74/782 [=>............................] - ETA: 11:01 - loss: 2.5715 - accuracy: 0.0092\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 77/782 [=>............................] - ETA: 10:56 - loss: 2.5682 - accuracy: 0.0096\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 80/782 [==>...........................] - ETA: 10:51 - loss: 2.5642 - accuracy: 0.0100\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 83/782 [==>...........................] - ETA: 10:46 - loss: 2.5670 - accuracy: 0.0104\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 86/782 [==>...........................] - ETA: 10:43 - loss: 2.5502 - accuracy: 0.0107\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 89/782 [==>...........................] - ETA: 10:42 - loss: 2.5412 - accuracy: 0.0111\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 92/782 [==>...........................] - ETA: 10:42 - loss: 2.5404 - accuracy: 0.0114\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 95/782 [==>...........................] - ETA: 10:45 - loss: 2.5315 - accuracy: 0.0116\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      " 98/782 [==>...........................] - ETA: 10:45 - loss: 2.5255 - accuracy: 0.0119\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "101/782 [==>...........................] - ETA: 10:40 - loss: 2.5215 - accuracy: 0.0122\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "104/782 [==>...........................] - ETA: 10:35 - loss: 2.5215 - accuracy: 0.0124\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "107/782 [===>..........................] - ETA: 10:31 - loss: 2.5156 - accuracy: 0.0126\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "110/782 [===>..........................] - ETA: 10:35 - loss: 2.5115 - accuracy: 0.0128\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "113/782 [===>..........................] - ETA: 10:30 - loss: 2.5159 - accuracy: 0.0130\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "116/782 [===>..........................] - ETA: 10:35 - loss: 2.5107 - accuracy: 0.0132\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "119/782 [===>..........................] - ETA: 10:31 - loss: 2.5019 - accuracy: 0.0134\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "122/782 [===>..........................] - ETA: 10:31 - loss: 2.4973 - accuracy: 0.0136\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "125/782 [===>..........................] - ETA: 10:31 - loss: 2.4972 - accuracy: 0.0137\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "128/782 [===>..........................] - ETA: 10:36 - loss: 2.4960 - accuracy: 0.0139\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "131/782 [====>.........................] - ETA: 10:35 - loss: 2.4937 - accuracy: 0.0141\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "134/782 [====>.........................] - ETA: 10:37 - loss: 2.4937 - accuracy: 0.0142\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "137/782 [====>.........................] - ETA: 10:34 - loss: 2.4926 - accuracy: 0.0143\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "140/782 [====>.........................] - ETA: 10:30 - loss: 2.4866 - accuracy: 0.0145\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "143/782 [====>.........................] - ETA: 10:29 - loss: 2.4852 - accuracy: 0.0146\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "146/782 [====>.........................] - ETA: 10:28 - loss: 2.4881 - accuracy: 0.0147\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "149/782 [====>.........................] - ETA: 10:27 - loss: 2.4876 - accuracy: 0.0148\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "152/782 [====>.........................] - ETA: 10:23 - loss: 2.4837 - accuracy: 0.0149\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "155/782 [====>.........................] - ETA: 10:22 - loss: 2.4816 - accuracy: 0.0150\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "158/782 [=====>........................] - ETA: 10:20 - loss: 2.4801 - accuracy: 0.0151\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "161/782 [=====>........................] - ETA: 10:23 - loss: 2.4781 - accuracy: 0.0152\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "164/782 [=====>........................] - ETA: 10:21 - loss: 2.4737 - accuracy: 0.0153\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "167/782 [=====>........................] - ETA: 10:21 - loss: 2.4730 - accuracy: 0.0154\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "170/782 [=====>........................] - ETA: 10:18 - loss: 2.4734 - accuracy: 0.0155\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "173/782 [=====>........................] - ETA: 10:13 - loss: 2.4726 - accuracy: 0.0156\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "176/782 [=====>........................] - ETA: 10:08 - loss: 2.4719 - accuracy: 0.0157\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "179/782 [=====>........................] - ETA: 10:04 - loss: 2.4731 - accuracy: 0.0158\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "182/782 [=====>........................] - ETA: 10:02 - loss: 2.4700 - accuracy: 0.0158\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "185/782 [======>.......................] - ETA: 10:00 - loss: 2.4680 - accuracy: 0.0159\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "188/782 [======>.......................] - ETA: 9:58 - loss: 2.4674 - accuracy: 0.0160 \n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "191/782 [======>.......................] - ETA: 9:53 - loss: 2.4660 - accuracy: 0.0160\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "194/782 [======>.......................] - ETA: 9:49 - loss: 2.4643 - accuracy: 0.0161\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "197/782 [======>.......................] - ETA: 9:45 - loss: 2.4576 - accuracy: 0.0162\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "200/782 [======>.......................] - ETA: 9:41 - loss: 2.4537 - accuracy: 0.0162\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "203/782 [======>.......................] - ETA: 9:37 - loss: 2.4493 - accuracy: 0.0163\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "206/782 [======>.......................] - ETA: 9:35 - loss: 2.4430 - accuracy: 0.0164\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "209/782 [=======>......................] - ETA: 9:31 - loss: 2.4392 - accuracy: 0.0164\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "212/782 [=======>......................] - ETA: 9:29 - loss: 2.4351 - accuracy: 0.0165\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "215/782 [=======>......................] - ETA: 9:27 - loss: 2.4321 - accuracy: 0.0165\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "218/782 [=======>......................] - ETA: 9:24 - loss: 2.4298 - accuracy: 0.0166\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "221/782 [=======>......................] - ETA: 9:22 - loss: 2.4264 - accuracy: 0.0166\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "224/782 [=======>......................] - ETA: 9:19 - loss: 2.4221 - accuracy: 0.0167\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "227/782 [=======>......................] - ETA: 9:18 - loss: 2.4176 - accuracy: 0.0167\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "230/782 [=======>......................] - ETA: 9:15 - loss: 2.4148 - accuracy: 0.0168\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "233/782 [=======>......................] - ETA: 9:11 - loss: 2.4128 - accuracy: 0.0168\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "236/782 [========>.....................] - ETA: 9:07 - loss: 2.4103 - accuracy: 0.0169\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "239/782 [========>.....................] - ETA: 9:03 - loss: 2.4056 - accuracy: 0.0169\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "242/782 [========>.....................] - ETA: 9:00 - loss: 2.4025 - accuracy: 0.0170\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "245/782 [========>.....................] - ETA: 8:56 - loss: 2.4021 - accuracy: 0.0170\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "248/782 [========>.....................] - ETA: 8:52 - loss: 2.4014 - accuracy: 0.0171\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "251/782 [========>.....................] - ETA: 8:49 - loss: 2.4008 - accuracy: 0.0171\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "254/782 [========>.....................] - ETA: 8:45 - loss: 2.4000 - accuracy: 0.0171\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "257/782 [========>.....................] - ETA: 8:41 - loss: 2.3945 - accuracy: 0.0172\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "260/782 [========>.....................] - ETA: 8:38 - loss: 2.3943 - accuracy: 0.0172\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "263/782 [=========>....................] - ETA: 8:34 - loss: 2.3929 - accuracy: 0.0172\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "266/782 [=========>....................] - ETA: 8:31 - loss: 2.3917 - accuracy: 0.0173\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "269/782 [=========>....................] - ETA: 8:28 - loss: 2.3882 - accuracy: 0.0173\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "272/782 [=========>....................] - ETA: 8:24 - loss: 2.3856 - accuracy: 0.0173\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "275/782 [=========>....................] - ETA: 8:20 - loss: 2.3840 - accuracy: 0.0174\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "278/782 [=========>....................] - ETA: 8:17 - loss: 2.3825 - accuracy: 0.0174\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "281/782 [=========>....................] - ETA: 8:14 - loss: 2.3811 - accuracy: 0.0174\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "284/782 [=========>....................] - ETA: 8:10 - loss: 2.3808 - accuracy: 0.0175\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "287/782 [==========>...................] - ETA: 8:07 - loss: 2.3785 - accuracy: 0.0175\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "290/782 [==========>...................] - ETA: 8:03 - loss: 2.3770 - accuracy: 0.0175\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "293/782 [==========>...................] - ETA: 8:00 - loss: 2.3747 - accuracy: 0.0176\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "296/782 [==========>...................] - ETA: 7:57 - loss: 2.3748 - accuracy: 0.0176\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "299/782 [==========>...................] - ETA: 7:54 - loss: 2.3724 - accuracy: 0.0176\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "302/782 [==========>...................] - ETA: 7:50 - loss: 2.3707 - accuracy: 0.0177\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "305/782 [==========>...................] - ETA: 7:47 - loss: 2.3681 - accuracy: 0.0177\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "308/782 [==========>...................] - ETA: 7:44 - loss: 2.3658 - accuracy: 0.0177\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "311/782 [==========>...................] - ETA: 7:40 - loss: 2.3662 - accuracy: 0.0177\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "314/782 [===========>..................] - ETA: 7:37 - loss: 2.3651 - accuracy: 0.0178\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "317/782 [===========>..................] - ETA: 7:34 - loss: 2.3619 - accuracy: 0.0178\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "320/782 [===========>..................] - ETA: 7:32 - loss: 2.3577 - accuracy: 0.0178\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "323/782 [===========>..................] - ETA: 7:28 - loss: 2.3569 - accuracy: 0.0178\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "326/782 [===========>..................] - ETA: 7:25 - loss: 2.3550 - accuracy: 0.0179\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "329/782 [===========>..................] - ETA: 7:22 - loss: 2.3542 - accuracy: 0.0179\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "332/782 [===========>..................] - ETA: 7:18 - loss: 2.3518 - accuracy: 0.0179\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "335/782 [===========>..................] - ETA: 7:15 - loss: 2.3503 - accuracy: 0.0179\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "338/782 [===========>..................] - ETA: 7:12 - loss: 2.3473 - accuracy: 0.0179\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "341/782 [============>.................] - ETA: 7:08 - loss: 2.3447 - accuracy: 0.0180\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "344/782 [============>.................] - ETA: 7:05 - loss: 2.3410 - accuracy: 0.0180\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "347/782 [============>.................] - ETA: 7:02 - loss: 2.3378 - accuracy: 0.0180\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "350/782 [============>.................] - ETA: 6:59 - loss: 2.3359 - accuracy: 0.0180\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "353/782 [============>.................] - ETA: 6:56 - loss: 2.3345 - accuracy: 0.0180\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "356/782 [============>.................] - ETA: 6:52 - loss: 2.3334 - accuracy: 0.0181\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "359/782 [============>.................] - ETA: 6:49 - loss: 2.3323 - accuracy: 0.0181\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "362/782 [============>.................] - ETA: 6:46 - loss: 2.3306 - accuracy: 0.0181\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "365/782 [=============>................] - ETA: 6:43 - loss: 2.3287 - accuracy: 0.0181\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "368/782 [=============>................] - ETA: 6:40 - loss: 2.3287 - accuracy: 0.0181\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "371/782 [=============>................] - ETA: 6:36 - loss: 2.3270 - accuracy: 0.0182\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "374/782 [=============>................] - ETA: 6:33 - loss: 2.3253 - accuracy: 0.0182\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "377/782 [=============>................] - ETA: 6:30 - loss: 2.3233 - accuracy: 0.0182\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "380/782 [=============>................] - ETA: 6:27 - loss: 2.3205 - accuracy: 0.0182\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "383/782 [=============>................] - ETA: 6:24 - loss: 2.3192 - accuracy: 0.0182\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "386/782 [=============>................] - ETA: 6:20 - loss: 2.3171 - accuracy: 0.0183\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "389/782 [=============>................] - ETA: 6:17 - loss: 2.3169 - accuracy: 0.0183\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "392/782 [==============>...............] - ETA: 6:14 - loss: 2.3157 - accuracy: 0.0183\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "395/782 [==============>...............] - ETA: 6:11 - loss: 2.3138 - accuracy: 0.0183\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "398/782 [==============>...............] - ETA: 6:08 - loss: 2.3113 - accuracy: 0.0183\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "401/782 [==============>...............] - ETA: 6:05 - loss: 2.3095 - accuracy: 0.0183\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "404/782 [==============>...............] - ETA: 6:02 - loss: 2.3079 - accuracy: 0.0183\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "407/782 [==============>...............] - ETA: 5:59 - loss: 2.3066 - accuracy: 0.0184\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "410/782 [==============>...............] - ETA: 5:56 - loss: 2.3046 - accuracy: 0.0184\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "413/782 [==============>...............] - ETA: 5:53 - loss: 2.3031 - accuracy: 0.0184\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "416/782 [==============>...............] - ETA: 5:50 - loss: 2.3019 - accuracy: 0.0184\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "419/782 [===============>..............] - ETA: 5:47 - loss: 2.3016 - accuracy: 0.0184\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "422/782 [===============>..............] - ETA: 5:44 - loss: 2.2991 - accuracy: 0.0184\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "425/782 [===============>..............] - ETA: 5:41 - loss: 2.2977 - accuracy: 0.0184\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "428/782 [===============>..............] - ETA: 5:38 - loss: 2.2963 - accuracy: 0.0185\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "431/782 [===============>..............] - ETA: 5:35 - loss: 2.2945 - accuracy: 0.0185\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "434/782 [===============>..............] - ETA: 5:32 - loss: 2.2941 - accuracy: 0.0185\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "437/782 [===============>..............] - ETA: 5:29 - loss: 2.2931 - accuracy: 0.0185\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "440/782 [===============>..............] - ETA: 5:26 - loss: 2.2914 - accuracy: 0.0185\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "443/782 [===============>..............] - ETA: 5:23 - loss: 2.2911 - accuracy: 0.0185\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "446/782 [================>.............] - ETA: 5:20 - loss: 2.2917 - accuracy: 0.0185\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "449/782 [================>.............] - ETA: 5:17 - loss: 2.2901 - accuracy: 0.0186\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "452/782 [================>.............] - ETA: 5:14 - loss: 2.2886 - accuracy: 0.0186\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "455/782 [================>.............] - ETA: 5:11 - loss: 2.2867 - accuracy: 0.0186\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "458/782 [================>.............] - ETA: 5:08 - loss: 2.2858 - accuracy: 0.0186\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "461/782 [================>.............] - ETA: 5:05 - loss: 2.2845 - accuracy: 0.0186\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "464/782 [================>.............] - ETA: 5:02 - loss: 2.2839 - accuracy: 0.0186\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "467/782 [================>.............] - ETA: 4:59 - loss: 2.2836 - accuracy: 0.0186\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "470/782 [=================>............] - ETA: 4:56 - loss: 2.2835 - accuracy: 0.0186\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "473/782 [=================>............] - ETA: 4:53 - loss: 2.2830 - accuracy: 0.0186\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "476/782 [=================>............] - ETA: 4:51 - loss: 2.2842 - accuracy: 0.0187\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "479/782 [=================>............] - ETA: 4:48 - loss: 2.2845 - accuracy: 0.0187\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "482/782 [=================>............] - ETA: 4:45 - loss: 2.2835 - accuracy: 0.0187\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "485/782 [=================>............] - ETA: 4:42 - loss: 2.2839 - accuracy: 0.0187\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "488/782 [=================>............] - ETA: 4:39 - loss: 2.2829 - accuracy: 0.0187\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "491/782 [=================>............] - ETA: 4:36 - loss: 2.2824 - accuracy: 0.0187\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "494/782 [=================>............] - ETA: 4:33 - loss: 2.2796 - accuracy: 0.0187\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "497/782 [==================>...........] - ETA: 4:30 - loss: 2.2791 - accuracy: 0.0187\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "500/782 [==================>...........] - ETA: 4:27 - loss: 2.2785 - accuracy: 0.0187\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "503/782 [==================>...........] - ETA: 4:24 - loss: 2.2778 - accuracy: 0.0188\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "506/782 [==================>...........] - ETA: 4:21 - loss: 2.2767 - accuracy: 0.0188\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "509/782 [==================>...........] - ETA: 4:18 - loss: 2.2755 - accuracy: 0.0188\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "512/782 [==================>...........] - ETA: 4:15 - loss: 2.2750 - accuracy: 0.0188\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "515/782 [==================>...........] - ETA: 4:12 - loss: 2.2745 - accuracy: 0.0188\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "518/782 [==================>...........] - ETA: 4:10 - loss: 2.2736 - accuracy: 0.0188\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "521/782 [==================>...........] - ETA: 4:07 - loss: 2.2733 - accuracy: 0.0188\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "524/782 [===================>..........] - ETA: 4:04 - loss: 2.2721 - accuracy: 0.0188\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "527/782 [===================>..........] - ETA: 4:01 - loss: 2.2706 - accuracy: 0.0188\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "530/782 [===================>..........] - ETA: 3:58 - loss: 2.2707 - accuracy: 0.0188\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "533/782 [===================>..........] - ETA: 3:55 - loss: 2.2693 - accuracy: 0.0188\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "536/782 [===================>..........] - ETA: 3:52 - loss: 2.2687 - accuracy: 0.0189\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "539/782 [===================>..........] - ETA: 3:49 - loss: 2.2679 - accuracy: 0.0189\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "542/782 [===================>..........] - ETA: 3:46 - loss: 2.2671 - accuracy: 0.0189\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "545/782 [===================>..........] - ETA: 3:43 - loss: 2.2659 - accuracy: 0.0189\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "548/782 [====================>.........] - ETA: 3:41 - loss: 2.2638 - accuracy: 0.0189\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "551/782 [====================>.........] - ETA: 3:38 - loss: 2.2639 - accuracy: 0.0189\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "554/782 [====================>.........] - ETA: 3:35 - loss: 2.2631 - accuracy: 0.0189\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "557/782 [====================>.........] - ETA: 3:32 - loss: 2.2621 - accuracy: 0.0189\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "560/782 [====================>.........] - ETA: 3:29 - loss: 2.2617 - accuracy: 0.0189\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "563/782 [====================>.........] - ETA: 3:26 - loss: 2.2608 - accuracy: 0.0189\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "566/782 [====================>.........] - ETA: 3:23 - loss: 2.2613 - accuracy: 0.0189\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "569/782 [====================>.........] - ETA: 3:20 - loss: 2.2603 - accuracy: 0.0189\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "572/782 [====================>.........] - ETA: 3:18 - loss: 2.2588 - accuracy: 0.0190\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "575/782 [=====================>........] - ETA: 3:15 - loss: 2.2572 - accuracy: 0.0190\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "578/782 [=====================>........] - ETA: 3:12 - loss: 2.2554 - accuracy: 0.0190\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "581/782 [=====================>........] - ETA: 3:09 - loss: 2.2551 - accuracy: 0.0190\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "584/782 [=====================>........] - ETA: 3:06 - loss: 2.2543 - accuracy: 0.0190\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "587/782 [=====================>........] - ETA: 3:03 - loss: 2.2532 - accuracy: 0.0190\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "590/782 [=====================>........] - ETA: 3:00 - loss: 2.2531 - accuracy: 0.0190\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "593/782 [=====================>........] - ETA: 2:57 - loss: 2.2526 - accuracy: 0.0190\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "596/782 [=====================>........] - ETA: 2:55 - loss: 2.2517 - accuracy: 0.0190\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "599/782 [=====================>........] - ETA: 2:52 - loss: 2.2521 - accuracy: 0.0190\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "602/782 [======================>.......] - ETA: 2:49 - loss: 2.2516 - accuracy: 0.0190\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "605/782 [======================>.......] - ETA: 2:46 - loss: 2.2518 - accuracy: 0.0190\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "608/782 [======================>.......] - ETA: 2:44 - loss: 2.2511 - accuracy: 0.0190\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "611/782 [======================>.......] - ETA: 2:41 - loss: 2.2502 - accuracy: 0.0190\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "614/782 [======================>.......] - ETA: 2:39 - loss: 2.2494 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "617/782 [======================>.......] - ETA: 2:36 - loss: 2.2491 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "620/782 [======================>.......] - ETA: 2:33 - loss: 2.2490 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "623/782 [======================>.......] - ETA: 2:30 - loss: 2.2489 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "626/782 [=======================>......] - ETA: 2:28 - loss: 2.2483 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "629/782 [=======================>......] - ETA: 2:25 - loss: 2.2476 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "632/782 [=======================>......] - ETA: 2:22 - loss: 2.2476 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "635/782 [=======================>......] - ETA: 2:20 - loss: 2.2467 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "638/782 [=======================>......] - ETA: 2:17 - loss: 2.2463 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "641/782 [=======================>......] - ETA: 2:14 - loss: 2.2455 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "644/782 [=======================>......] - ETA: 2:12 - loss: 2.2452 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "647/782 [=======================>......] - ETA: 2:09 - loss: 2.2441 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "650/782 [=======================>......] - ETA: 2:06 - loss: 2.2433 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "653/782 [========================>.....] - ETA: 2:03 - loss: 2.2428 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "656/782 [========================>.....] - ETA: 2:00 - loss: 2.2421 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "659/782 [========================>.....] - ETA: 1:57 - loss: 2.2415 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "662/782 [========================>.....] - ETA: 1:54 - loss: 2.2400 - accuracy: 0.0191\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "665/782 [========================>.....] - ETA: 1:51 - loss: 2.2396 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "668/782 [========================>.....] - ETA: 1:48 - loss: 2.2393 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "671/782 [========================>.....] - ETA: 1:45 - loss: 2.2395 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "674/782 [========================>.....] - ETA: 1:43 - loss: 2.2394 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "677/782 [========================>.....] - ETA: 1:40 - loss: 2.2390 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "680/782 [=========================>....] - ETA: 1:37 - loss: 2.2384 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "683/782 [=========================>....] - ETA: 1:34 - loss: 2.2376 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "686/782 [=========================>....] - ETA: 1:31 - loss: 2.2365 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "689/782 [=========================>....] - ETA: 1:28 - loss: 2.2364 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "692/782 [=========================>....] - ETA: 1:25 - loss: 2.2352 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "695/782 [=========================>....] - ETA: 1:22 - loss: 2.2338 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "698/782 [=========================>....] - ETA: 1:20 - loss: 2.2337 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "701/782 [=========================>....] - ETA: 1:17 - loss: 2.2332 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "704/782 [==========================>...] - ETA: 1:14 - loss: 2.2320 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "707/782 [==========================>...] - ETA: 1:11 - loss: 2.2313 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "710/782 [==========================>...] - ETA: 1:08 - loss: 2.2306 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "713/782 [==========================>...] - ETA: 1:05 - loss: 2.2296 - accuracy: 0.0192\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "716/782 [==========================>...] - ETA: 1:02 - loss: 2.2289 - accuracy: 0.0193\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "719/782 [==========================>...] - ETA: 59s - loss: 2.2282 - accuracy: 0.0193 \n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "722/782 [==========================>...] - ETA: 57s - loss: 2.2274 - accuracy: 0.0193\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "725/782 [==========================>...] - ETA: 54s - loss: 2.2265 - accuracy: 0.0193\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "728/782 [==========================>...] - ETA: 51s - loss: 2.2260 - accuracy: 0.0193\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "731/782 [===========================>..] - ETA: 48s - loss: 2.2253 - accuracy: 0.0193\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "734/782 [===========================>..] - ETA: 45s - loss: 2.2239 - accuracy: 0.0193\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "737/782 [===========================>..] - ETA: 42s - loss: 2.2239 - accuracy: 0.0193\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "740/782 [===========================>..] - ETA: 39s - loss: 2.2241 - accuracy: 0.0193\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "743/782 [===========================>..] - ETA: 37s - loss: 2.2235 - accuracy: 0.0193\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "746/782 [===========================>..] - ETA: 34s - loss: 2.2230 - accuracy: 0.0193\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "749/782 [===========================>..] - ETA: 31s - loss: 2.2220 - accuracy: 0.0193\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "752/782 [===========================>..] - ETA: 28s - loss: 2.2220 - accuracy: 0.0193\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "755/782 [===========================>..] - ETA: 25s - loss: 2.2219 - accuracy: 0.0193\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "758/782 [============================>.] - ETA: 22s - loss: 2.2209 - accuracy: 0.0193\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "761/782 [============================>.] - ETA: 19s - loss: 2.2216 - accuracy: 0.0194\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "764/782 [============================>.] - ETA: 17s - loss: 2.2205 - accuracy: 0.0194\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "767/782 [============================>.] - ETA: 14s - loss: 2.2207 - accuracy: 0.0194\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "770/782 [============================>.] - ETA: 11s - loss: 2.2207 - accuracy: 0.0194\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "773/782 [============================>.] - ETA: 8s - loss: 2.2210 - accuracy: 0.0194\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "776/782 [============================>.] - ETA: 5s - loss: 2.2205 - accuracy: 0.0194\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "779/782 [============================>.] - ETA: 2s - loss: 2.2199 - accuracy: 0.0194\n",
      "Epoch 1: saving model to training_small\\cp-0001.ckpt\n",
      "782/782 [==============================] - 747s 947ms/step - loss: 2.2199 - accuracy: 0.0194\n",
      "Epoch 2/40\n",
      "\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "  3/782 [..............................] - ETA: 4:39 - loss: 2.0844 - accuracy: 0.0213\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "  6/782 [..............................] - ETA: 8:40 - loss: 2.0124 - accuracy: 0.0217\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "  9/782 [..............................] - ETA: 9:36 - loss: 1.9621 - accuracy: 0.0216 \n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 12/782 [..............................] - ETA: 10:09 - loss: 1.9583 - accuracy: 0.0214\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 15/782 [..............................] - ETA: 10:21 - loss: 1.9430 - accuracy: 0.0215\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 18/782 [..............................] - ETA: 10:31 - loss: 1.9086 - accuracy: 0.0214\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 21/782 [..............................] - ETA: 10:32 - loss: 1.9455 - accuracy: 0.0213\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 24/782 [..............................] - ETA: 10:35 - loss: 1.9437 - accuracy: 0.0214\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 27/782 [>.............................] - ETA: 10:35 - loss: 1.9455 - accuracy: 0.0214\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 30/782 [>.............................] - ETA: 10:39 - loss: 1.9471 - accuracy: 0.0214\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 33/782 [>.............................] - ETA: 10:40 - loss: 1.9389 - accuracy: 0.0214\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 36/782 [>.............................] - ETA: 10:38 - loss: 1.9302 - accuracy: 0.0214\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 39/782 [>.............................] - ETA: 10:36 - loss: 1.9344 - accuracy: 0.0215\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 42/782 [>.............................] - ETA: 10:43 - loss: 1.9377 - accuracy: 0.0215\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 45/782 [>.............................] - ETA: 10:52 - loss: 1.9430 - accuracy: 0.0216\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 48/782 [>.............................] - ETA: 10:55 - loss: 1.9479 - accuracy: 0.0217\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 51/782 [>.............................] - ETA: 10:51 - loss: 1.9508 - accuracy: 0.0217\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 54/782 [=>............................] - ETA: 10:52 - loss: 1.9601 - accuracy: 0.0217\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 57/782 [=>............................] - ETA: 10:51 - loss: 1.9627 - accuracy: 0.0217\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 60/782 [=>............................] - ETA: 10:46 - loss: 1.9604 - accuracy: 0.0217\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 63/782 [=>............................] - ETA: 10:44 - loss: 1.9577 - accuracy: 0.0217\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 66/782 [=>............................] - ETA: 10:42 - loss: 1.9594 - accuracy: 0.0218\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 69/782 [=>............................] - ETA: 10:39 - loss: 1.9536 - accuracy: 0.0218\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 72/782 [=>............................] - ETA: 10:37 - loss: 1.9519 - accuracy: 0.0218\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 75/782 [=>............................] - ETA: 10:34 - loss: 1.9426 - accuracy: 0.0218\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 78/782 [=>............................] - ETA: 10:31 - loss: 1.9402 - accuracy: 0.0218\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 81/782 [==>...........................] - ETA: 10:28 - loss: 1.9417 - accuracy: 0.0218\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 84/782 [==>...........................] - ETA: 10:25 - loss: 1.9420 - accuracy: 0.0218\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 87/782 [==>...........................] - ETA: 10:22 - loss: 1.9400 - accuracy: 0.0218\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 90/782 [==>...........................] - ETA: 10:22 - loss: 1.9400 - accuracy: 0.0219\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 93/782 [==>...........................] - ETA: 10:18 - loss: 1.9407 - accuracy: 0.0220\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 96/782 [==>...........................] - ETA: 10:16 - loss: 1.9425 - accuracy: 0.0221\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      " 99/782 [==>...........................] - ETA: 10:13 - loss: 1.9421 - accuracy: 0.0221\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "102/782 [==>...........................] - ETA: 10:11 - loss: 1.9402 - accuracy: 0.0221\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "105/782 [===>..........................] - ETA: 10:07 - loss: 1.9353 - accuracy: 0.0221\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "108/782 [===>..........................] - ETA: 10:05 - loss: 1.9387 - accuracy: 0.0221\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "111/782 [===>..........................] - ETA: 10:03 - loss: 1.9372 - accuracy: 0.0221\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "114/782 [===>..........................] - ETA: 10:00 - loss: 1.9357 - accuracy: 0.0221\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "117/782 [===>..........................] - ETA: 10:00 - loss: 1.9335 - accuracy: 0.0222\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "120/782 [===>..........................] - ETA: 10:01 - loss: 1.9325 - accuracy: 0.0222\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "123/782 [===>..........................] - ETA: 9:59 - loss: 1.9322 - accuracy: 0.0222 \n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "126/782 [===>..........................] - ETA: 9:59 - loss: 1.9335 - accuracy: 0.0223 \n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "129/782 [===>..........................] - ETA: 10:01 - loss: 1.9345 - accuracy: 0.0223\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "132/782 [====>.........................] - ETA: 10:00 - loss: 1.9337 - accuracy: 0.0223\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "135/782 [====>.........................] - ETA: 10:00 - loss: 1.9363 - accuracy: 0.0224\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "138/782 [====>.........................] - ETA: 10:02 - loss: 1.9344 - accuracy: 0.0224\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "141/782 [====>.........................] - ETA: 10:03 - loss: 1.9329 - accuracy: 0.0225\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "144/782 [====>.........................] - ETA: 10:03 - loss: 1.9341 - accuracy: 0.0225\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "147/782 [====>.........................] - ETA: 10:03 - loss: 1.9361 - accuracy: 0.0225\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "150/782 [====>.........................] - ETA: 10:03 - loss: 1.9377 - accuracy: 0.0226\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "153/782 [====>.........................] - ETA: 9:59 - loss: 1.9383 - accuracy: 0.0226 \n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "156/782 [====>.........................] - ETA: 9:58 - loss: 1.9369 - accuracy: 0.0226 \n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "159/782 [=====>........................] - ETA: 9:58 - loss: 1.9371 - accuracy: 0.0226 \n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "162/782 [=====>........................] - ETA: 9:56 - loss: 1.9369 - accuracy: 0.0227 \n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "165/782 [=====>........................] - ETA: 9:55 - loss: 1.9375 - accuracy: 0.0227\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "168/782 [=====>........................] - ETA: 9:54 - loss: 1.9360 - accuracy: 0.0227\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "171/782 [=====>........................] - ETA: 9:55 - loss: 1.9381 - accuracy: 0.0227\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "174/782 [=====>........................] - ETA: 9:54 - loss: 1.9376 - accuracy: 0.0228\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "177/782 [=====>........................] - ETA: 9:53 - loss: 1.9378 - accuracy: 0.0228\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "180/782 [=====>........................] - ETA: 9:49 - loss: 1.9371 - accuracy: 0.0228\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "183/782 [======>.......................] - ETA: 9:48 - loss: 1.9351 - accuracy: 0.0228\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "186/782 [======>.......................] - ETA: 9:47 - loss: 1.9325 - accuracy: 0.0228\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "189/782 [======>.......................] - ETA: 9:45 - loss: 1.9297 - accuracy: 0.0228\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "192/782 [======>.......................] - ETA: 9:41 - loss: 1.9306 - accuracy: 0.0228\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "195/782 [======>.......................] - ETA: 9:38 - loss: 1.9320 - accuracy: 0.0228\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "198/782 [======>.......................] - ETA: 9:34 - loss: 1.9313 - accuracy: 0.0228\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "201/782 [======>.......................] - ETA: 9:30 - loss: 1.9313 - accuracy: 0.0228\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "204/782 [======>.......................] - ETA: 9:26 - loss: 1.9282 - accuracy: 0.0229\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "207/782 [======>.......................] - ETA: 9:23 - loss: 1.9259 - accuracy: 0.0229\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "210/782 [=======>......................] - ETA: 9:19 - loss: 1.9248 - accuracy: 0.0229\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "213/782 [=======>......................] - ETA: 9:15 - loss: 1.9249 - accuracy: 0.0229\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "216/782 [=======>......................] - ETA: 9:11 - loss: 1.9267 - accuracy: 0.0229\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "219/782 [=======>......................] - ETA: 9:07 - loss: 1.9237 - accuracy: 0.0229\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "222/782 [=======>......................] - ETA: 9:04 - loss: 1.9221 - accuracy: 0.0229\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "225/782 [=======>......................] - ETA: 9:00 - loss: 1.9203 - accuracy: 0.0229\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "228/782 [=======>......................] - ETA: 8:57 - loss: 1.9196 - accuracy: 0.0229\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "231/782 [=======>......................] - ETA: 8:53 - loss: 1.9195 - accuracy: 0.0229\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "234/782 [=======>......................] - ETA: 8:50 - loss: 1.9219 - accuracy: 0.0230\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "237/782 [========>.....................] - ETA: 8:47 - loss: 1.9194 - accuracy: 0.0230\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "240/782 [========>.....................] - ETA: 8:44 - loss: 1.9192 - accuracy: 0.0230\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "243/782 [========>.....................] - ETA: 8:40 - loss: 1.9210 - accuracy: 0.0230\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "246/782 [========>.....................] - ETA: 8:37 - loss: 1.9221 - accuracy: 0.0230\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "249/782 [========>.....................] - ETA: 8:34 - loss: 1.9219 - accuracy: 0.0230\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "252/782 [========>.....................] - ETA: 8:30 - loss: 1.9238 - accuracy: 0.0230\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "255/782 [========>.....................] - ETA: 8:27 - loss: 1.9252 - accuracy: 0.0231\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "258/782 [========>.....................] - ETA: 8:24 - loss: 1.9252 - accuracy: 0.0231\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "261/782 [=========>....................] - ETA: 8:20 - loss: 1.9271 - accuracy: 0.0231\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "264/782 [=========>....................] - ETA: 8:17 - loss: 1.9268 - accuracy: 0.0231\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "267/782 [=========>....................] - ETA: 8:14 - loss: 1.9280 - accuracy: 0.0231\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "270/782 [=========>....................] - ETA: 8:10 - loss: 1.9287 - accuracy: 0.0231\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "273/782 [=========>....................] - ETA: 8:07 - loss: 1.9260 - accuracy: 0.0231\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "276/782 [=========>....................] - ETA: 8:04 - loss: 1.9256 - accuracy: 0.0231\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "279/782 [=========>....................] - ETA: 8:01 - loss: 1.9270 - accuracy: 0.0231\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "282/782 [=========>....................] - ETA: 7:59 - loss: 1.9263 - accuracy: 0.0231\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "285/782 [=========>....................] - ETA: 7:56 - loss: 1.9278 - accuracy: 0.0232\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "288/782 [==========>...................] - ETA: 7:52 - loss: 1.9284 - accuracy: 0.0232\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "291/782 [==========>...................] - ETA: 7:49 - loss: 1.9298 - accuracy: 0.0232\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "294/782 [==========>...................] - ETA: 7:46 - loss: 1.9297 - accuracy: 0.0232\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "297/782 [==========>...................] - ETA: 7:43 - loss: 1.9301 - accuracy: 0.0232\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "300/782 [==========>...................] - ETA: 7:40 - loss: 1.9266 - accuracy: 0.0232\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "303/782 [==========>...................] - ETA: 7:37 - loss: 1.9276 - accuracy: 0.0232\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "306/782 [==========>...................] - ETA: 7:34 - loss: 1.9277 - accuracy: 0.0232\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "309/782 [==========>...................] - ETA: 7:31 - loss: 1.9285 - accuracy: 0.0233\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "312/782 [==========>...................] - ETA: 7:28 - loss: 1.9281 - accuracy: 0.0233\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "315/782 [===========>..................] - ETA: 7:25 - loss: 1.9279 - accuracy: 0.0233\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "318/782 [===========>..................] - ETA: 7:22 - loss: 1.9273 - accuracy: 0.0233\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "321/782 [===========>..................] - ETA: 7:19 - loss: 1.9266 - accuracy: 0.0233\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "324/782 [===========>..................] - ETA: 7:16 - loss: 1.9281 - accuracy: 0.0233\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "327/782 [===========>..................] - ETA: 7:13 - loss: 1.9282 - accuracy: 0.0233\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "330/782 [===========>..................] - ETA: 7:09 - loss: 1.9271 - accuracy: 0.0233\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "333/782 [===========>..................] - ETA: 7:06 - loss: 1.9272 - accuracy: 0.0233\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "336/782 [===========>..................] - ETA: 7:04 - loss: 1.9278 - accuracy: 0.0234\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "339/782 [============>.................] - ETA: 7:01 - loss: 1.9291 - accuracy: 0.0234\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "342/782 [============>.................] - ETA: 6:58 - loss: 1.9276 - accuracy: 0.0234\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "345/782 [============>.................] - ETA: 6:55 - loss: 1.9288 - accuracy: 0.0234\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "348/782 [============>.................] - ETA: 6:52 - loss: 1.9306 - accuracy: 0.0234\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "351/782 [============>.................] - ETA: 6:49 - loss: 1.9305 - accuracy: 0.0234\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "354/782 [============>.................] - ETA: 6:46 - loss: 1.9313 - accuracy: 0.0234\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "357/782 [============>.................] - ETA: 6:43 - loss: 1.9326 - accuracy: 0.0235\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "360/782 [============>.................] - ETA: 6:40 - loss: 1.9336 - accuracy: 0.0235\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "363/782 [============>.................] - ETA: 6:37 - loss: 1.9344 - accuracy: 0.0235\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "366/782 [=============>................] - ETA: 6:34 - loss: 1.9355 - accuracy: 0.0235\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "369/782 [=============>................] - ETA: 6:31 - loss: 1.9352 - accuracy: 0.0235\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "372/782 [=============>................] - ETA: 6:28 - loss: 1.9364 - accuracy: 0.0235\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "375/782 [=============>................] - ETA: 6:25 - loss: 1.9363 - accuracy: 0.0235\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "378/782 [=============>................] - ETA: 6:22 - loss: 1.9368 - accuracy: 0.0235\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "381/782 [=============>................] - ETA: 6:19 - loss: 1.9366 - accuracy: 0.0236\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "384/782 [=============>................] - ETA: 6:16 - loss: 1.9371 - accuracy: 0.0236\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "387/782 [=============>................] - ETA: 6:13 - loss: 1.9389 - accuracy: 0.0236\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "390/782 [=============>................] - ETA: 6:10 - loss: 1.9386 - accuracy: 0.0236\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "393/782 [==============>...............] - ETA: 6:07 - loss: 1.9398 - accuracy: 0.0236\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "396/782 [==============>...............] - ETA: 6:04 - loss: 1.9398 - accuracy: 0.0236\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "399/782 [==============>...............] - ETA: 6:01 - loss: 1.9394 - accuracy: 0.0236\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "402/782 [==============>...............] - ETA: 5:58 - loss: 1.9388 - accuracy: 0.0236\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "405/782 [==============>...............] - ETA: 5:55 - loss: 1.9380 - accuracy: 0.0236\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "408/782 [==============>...............] - ETA: 5:53 - loss: 1.9374 - accuracy: 0.0236\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "411/782 [==============>...............] - ETA: 5:50 - loss: 1.9375 - accuracy: 0.0236\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "414/782 [==============>...............] - ETA: 5:47 - loss: 1.9378 - accuracy: 0.0237\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "417/782 [==============>...............] - ETA: 5:44 - loss: 1.9380 - accuracy: 0.0237\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "420/782 [===============>..............] - ETA: 5:41 - loss: 1.9386 - accuracy: 0.0237\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "423/782 [===============>..............] - ETA: 5:39 - loss: 1.9385 - accuracy: 0.0237\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "426/782 [===============>..............] - ETA: 5:35 - loss: 1.9372 - accuracy: 0.0237\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "429/782 [===============>..............] - ETA: 5:32 - loss: 1.9382 - accuracy: 0.0237\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "432/782 [===============>..............] - ETA: 5:29 - loss: 1.9397 - accuracy: 0.0237\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "435/782 [===============>..............] - ETA: 5:26 - loss: 1.9412 - accuracy: 0.0237\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "438/782 [===============>..............] - ETA: 5:23 - loss: 1.9394 - accuracy: 0.0237\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "441/782 [===============>..............] - ETA: 5:21 - loss: 1.9389 - accuracy: 0.0237\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "444/782 [================>.............] - ETA: 5:18 - loss: 1.9384 - accuracy: 0.0237\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "447/782 [================>.............] - ETA: 5:15 - loss: 1.9389 - accuracy: 0.0237\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "450/782 [================>.............] - ETA: 5:12 - loss: 1.9395 - accuracy: 0.0237\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "453/782 [================>.............] - ETA: 5:09 - loss: 1.9405 - accuracy: 0.0238\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "456/782 [================>.............] - ETA: 5:06 - loss: 1.9403 - accuracy: 0.0238\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "459/782 [================>.............] - ETA: 5:03 - loss: 1.9404 - accuracy: 0.0238\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "462/782 [================>.............] - ETA: 5:00 - loss: 1.9406 - accuracy: 0.0238\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "465/782 [================>.............] - ETA: 4:57 - loss: 1.9407 - accuracy: 0.0238\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "468/782 [================>.............] - ETA: 4:55 - loss: 1.9408 - accuracy: 0.0238\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "471/782 [=================>............] - ETA: 4:52 - loss: 1.9414 - accuracy: 0.0239\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "474/782 [=================>............] - ETA: 4:49 - loss: 1.9412 - accuracy: 0.0239\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "477/782 [=================>............] - ETA: 4:46 - loss: 1.9426 - accuracy: 0.0239\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "480/782 [=================>............] - ETA: 4:43 - loss: 1.9430 - accuracy: 0.0239\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "483/782 [=================>............] - ETA: 4:40 - loss: 1.9441 - accuracy: 0.0239\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "486/782 [=================>............] - ETA: 4:37 - loss: 1.9456 - accuracy: 0.0239\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "489/782 [=================>............] - ETA: 4:34 - loss: 1.9474 - accuracy: 0.0240\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "492/782 [=================>............] - ETA: 4:31 - loss: 1.9473 - accuracy: 0.0240\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "495/782 [=================>............] - ETA: 4:29 - loss: 1.9477 - accuracy: 0.0240\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "498/782 [==================>...........] - ETA: 4:26 - loss: 1.9489 - accuracy: 0.0240\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "501/782 [==================>...........] - ETA: 4:23 - loss: 1.9496 - accuracy: 0.0240\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "504/782 [==================>...........] - ETA: 4:20 - loss: 1.9497 - accuracy: 0.0240\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "507/782 [==================>...........] - ETA: 4:17 - loss: 1.9493 - accuracy: 0.0240\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "510/782 [==================>...........] - ETA: 4:15 - loss: 1.9498 - accuracy: 0.0240\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "513/782 [==================>...........] - ETA: 4:12 - loss: 1.9492 - accuracy: 0.0241\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "516/782 [==================>...........] - ETA: 4:09 - loss: 1.9497 - accuracy: 0.0241\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "519/782 [==================>...........] - ETA: 4:06 - loss: 1.9501 - accuracy: 0.0241\n",
      "Epoch 2: saving model to training_small\\cp-0002.ckpt\n",
      "521/782 [==================>...........] - ETA: 4:04 - loss: 1.9520 - accuracy: 0.0241"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'transformer/outputs/Tensordot/MatMul' defined at (most recent call last):\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\YSH\\AppData\\Local\\Temp/ipykernel_1808/449592082.py\", line 2, in <module>\n      model.fit(dataset, epochs=EPOCHS, callbacks=[cp_callback])\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1370, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1013, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1002, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\", line 992, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\", line 851, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 993, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\functional.py\", line 450, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\functional.py\", line 588, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 993, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 222, in call\n      outputs = tf.tensordot(inputs, self.kernel, [[rank - 1], [0]])\nNode: 'transformer/outputs/Tensordot/MatMul'\nOOM when allocating tensor with shape[3136,62146] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node transformer/outputs/Tensordot/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_13660]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1808/449592082.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'transformer/outputs/Tensordot/MatMul' defined at (most recent call last):\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\YSH\\AppData\\Local\\Temp/ipykernel_1808/449592082.py\", line 2, in <module>\n      model.fit(dataset, epochs=EPOCHS, callbacks=[cp_callback])\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1370, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1013, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1002, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\", line 992, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\", line 851, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 993, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\functional.py\", line 450, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\functional.py\", line 588, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 993, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\YSH\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 222, in call\n      outputs = tf.tensordot(inputs, self.kernel, [[rank - 1], [0]])\nNode: 'transformer/outputs/Tensordot/MatMul'\nOOM when allocating tensor with shape[3136,62146] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node transformer/outputs/Tensordot/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_13660]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "model.fit(dataset, epochs=EPOCHS, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9585e0e58f3ada4c387d89b399b9d9bb88b52954ed4e2235f58d5a052e970ed6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
